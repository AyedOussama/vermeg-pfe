package com.pfe2025.ai_processing_service.service;

import com.pfe2025.ai_processing_service.config.TogetherAiConfig; // Injecter pour m√©tadonn√©es
import com.pfe2025.ai_processing_service.dto.CvParsedEventDto;
import com.pfe2025.ai_processing_service.dto.DocumentEventDto;
import com.pfe2025.ai_processing_service.exception.DocumentFetchException;
import com.pfe2025.ai_processing_service.util.JsonParserUtil;
// CORRECTION: Suppression de l'import @RequiredArgsConstructor
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.cloud.stream.function.StreamBridge;
import org.springframework.core.io.buffer.DataBuffer;
import org.springframework.core.io.buffer.DataBufferUtils;
import org.springframework.http.HttpStatus;
import org.springframework.http.HttpStatusCode;
import org.springframework.messaging.Message;
import org.springframework.messaging.support.MessageBuilder;
import org.springframework.stereotype.Service;
import org.springframework.web.reactive.function.client.WebClient;
import org.springframework.web.reactive.function.client.WebClientResponseException;
import reactor.core.publisher.Mono;
import reactor.util.function.Tuples;

import java.nio.ByteBuffer;
import java.time.Duration;
import java.time.LocalDateTime;

@Service
@Slf4j
// CORRECTION: Suppression de @RequiredArgsConstructor
public class AiProcessorService {

    private final PdfTextExtractor pdfTextExtractor;
    private final TogetherAiClient togetherAiClient;
    private final JsonParserUtil jsonParserUtil;
    private final StreamBridge streamBridge;
    private final LanguageDetectorService languageDetectorService;
    private final TogetherAiConfig togetherAiConfig; // Injecter pour le nom du mod√®le

    @Qualifier("documentServiceWebClient") // Qualifier pour choisir le bon WebClient
    private final WebClient documentServiceWebClient;

    private static final String CV_PARSED_BINDING = "cvParsed-out-0";
    // private static final String PROCESSING_FAILED_BINDING = "processingFailed-out-0"; // Si on publie les erreurs

    // CORRECTION: Ajout du constructeur explicite
    public AiProcessorService(PdfTextExtractor pdfTextExtractor,
                              TogetherAiClient togetherAiClient,
                              JsonParserUtil jsonParserUtil,
                              StreamBridge streamBridge,
                              LanguageDetectorService languageDetectorService,
                              TogetherAiConfig togetherAiConfig,
                              @Qualifier("documentServiceWebClient") WebClient documentServiceWebClient) {
        this.pdfTextExtractor = pdfTextExtractor;
        this.togetherAiClient = togetherAiClient;
        this.jsonParserUtil = jsonParserUtil;
        this.streamBridge = streamBridge;
        this.languageDetectorService = languageDetectorService;
        this.togetherAiConfig = togetherAiConfig;
        this.documentServiceWebClient = documentServiceWebClient;
    }
    /**
     * Orchestre le traitement complet d'un √©v√©nement de document CV.
     * T√©l√©charge, extrait, d√©tecte la langue, appelle l'IA, parse et publie le r√©sultat.
     * AM√âLIORATION: La gestion d'erreur est laiss√©e √† la propagation pour retry/DLQ.
     *
     * @param event L'√©v√©nement DocumentEventDto re√ßu.
     * @return Un Mono<Void> qui se termine quand le traitement est fini (succ√®s ou √©chec propag√©).
     */
    public Mono<Void> processCvAndPublishResult(DocumentEventDto event) {
        long startTime = System.currentTimeMillis();
        log.info("Starting CV processing pipeline for documentId: {}", event.getDocumentId());

        // 1. T√©l√©charger le PDF en byte[]
        return downloadPdfAsBytes(event.getDocumentId())
                // 2. Extraire le texte du PDF
                .flatMap(pdfBytes -> {
                    log.info("üìÑ EXTRACTION DE TEXTE - Document ID: {}", event.getDocumentId());
                    log.info("   üì¶ Taille PDF: {} bytes", pdfBytes.length);
                    return pdfTextExtractor.extractText(pdfBytes)
                            .doOnSuccess(text -> {
                                log.info("‚úÖ EXTRACTION R√âUSSIE - Document ID: {}", event.getDocumentId());
                                log.info("   üìù Longueur du texte extrait: {} caract√®res", text.length());
                                log.info("   üîç Aper√ßu du texte (100 premiers caract√®res): {}",
                                        text.length() > 100 ? text.substring(0, 100) + "..." : text);
                            });
                })
                // 3. D√©tecter la langue et la passer avec le texte
                .flatMap(cvText -> {
                    log.info("üåç D√âTECTION DE LANGUE - Document ID: {}", event.getDocumentId());
                    return languageDetectorService.detectLanguage(cvText.substring(0, Math.min(cvText.length(), 1000)))
                            .doOnSuccess(lang -> log.info("‚úÖ LANGUE D√âTECT√âE: {} - Document ID: {}", lang, event.getDocumentId()))
                            .map(lang -> Tuples.of(cvText, lang)); // Tuple<String, String>
                })
                // 4. Appeler l'IA et passer sa r√©ponse JSON et la langue d√©tect√©e
                .flatMap(textAndLangTuple -> {
                    String cvText = textAndLangTuple.getT1();
                    String detectedLanguage = textAndLangTuple.getT2();
                    log.info("ü§ñ ANALYSE IA - Document ID: {}", event.getDocumentId());
                    log.info("   üåç Langue: {}", detectedLanguage);
                    log.info("   üìù Longueur du texte √† analyser: {} caract√®res", cvText.length());
                    return togetherAiClient.extractCvDataFromText(cvText, detectedLanguage)
                            .doOnSuccess(response -> {
                                log.info("‚úÖ ANALYSE IA TERMIN√âE - Document ID: {}", event.getDocumentId());
                                log.info("   üìä R√©ponse JSON re√ßue (longueur: {} caract√®res)", response.length());
                            })
                            .map(aiJsonResponse -> Tuples.of(aiJsonResponse, detectedLanguage)); // Tuple<String, String>
                })
                // 5. Parser la r√©ponse JSON de l'IA
                .map(jsonAndLangTuple -> {
                    String aiJsonResponse = jsonAndLangTuple.getT1();
                    String detectedLanguage = jsonAndLangTuple.getT2();
                    CvParsedEventDto parsedDto = jsonParserUtil.safeParseCvJson(aiJsonResponse);
                    return Tuples.of(parsedDto, detectedLanguage); // Tuple<CvParsedEventDto, String>
                })
                // 6. Enrichir le DTO et publier l'√©v√©nement de succ√®s
                .flatMap(dtoAndLangTuple -> {
                    CvParsedEventDto parsedData = dtoAndLangTuple.getT1();
                    String detectedLanguage = dtoAndLangTuple.getT2();

                    // Enrichir avec les informations de l'√©v√©nement original et m√©tadonn√©es
                    parsedData.setKeycloakId(event.getKeycloakId());
                    parsedData.setDocumentId(event.getDocumentId());
                    parsedData.setCvLanguage(detectedLanguage); // Langue d√©tect√©e par Tika

                    if (parsedData.getAiMetadata() == null) {
                        parsedData.setAiMetadata(CvParsedEventDto.AiProcessingMetadata.builder().build());
                    }
                    parsedData.getAiMetadata().setDocumentId(String.valueOf(event.getDocumentId()));
                    parsedData.getAiMetadata().setProcessedAt(LocalDateTime.now());
                    parsedData.getAiMetadata().setDetectedLanguage(detectedLanguage);
                    parsedData.getAiMetadata().setModelUsed(togetherAiConfig.getModel()); // Ajouter le mod√®le utilis√©

                    // === AFFICHAGE D√âTAILL√â DU R√âSULTAT DE L'ANALYSE ATS ===
                    log.info("=== R√âSULTAT COMPLET DE L'ANALYSE ATS pour documentId: {} ===", event.getDocumentId());

                    // Informations personnelles (sans donn√©es sensibles)
                    if (parsedData.getPersonalInfo() != null) {
                        log.info("üë§ INFORMATIONS PERSONNELLES:");
                        log.info("   - Pr√©nom: {}", parsedData.getPersonalInfo().getFirstName());
                        log.info("   - Nom: {}", parsedData.getPersonalInfo().getLastName());
                    }

                    // Analyse ATS compl√®te
                    if (parsedData.getAtsAnalysis() != null) {
                        var ats = parsedData.getAtsAnalysis();
                        log.info("üéØ ANALYSE ATS COMPL√àTE:");
                        log.info("   üìä Score global: {}/100", ats.getOverallScore());
                        log.info("   üìù √âvaluation g√©n√©rale: {}", ats.getOverallAssessment());
                        log.info("   üîß Compatibilit√© ATS: {}", ats.getAtsCompatibility());
                        log.info("   ‚ö° Priorit√© d'am√©lioration: {}", ats.getImprovementPriority());

                        // D√©tail des scores
                        if (ats.getScoreBreakdown() != null) {
                            var scores = ats.getScoreBreakdown();
                            log.info("   üìà D√âTAIL DES SCORES:");
                            log.info("      - Format: {}/100", scores.getFormatScore());
                            log.info("      - Contenu: {}/100", scores.getContentScore());
                            log.info("      - Comp√©tences: {}/100", scores.getSkillsScore());
                            log.info("      - Exp√©rience: {}/100", scores.getExperienceScore());
                            if (scores.getScoreExplanation() != null) {
                                log.info("      - Explication: {}", scores.getScoreExplanation());
                            }
                        }

                        // Points forts
                        if (ats.getStrengths() != null && !ats.getStrengths().isEmpty()) {
                            log.info("   ‚úÖ POINTS FORTS ({} identifi√©s):", ats.getStrengths().size());
                            ats.getStrengths().forEach(strength -> log.info("      ‚Ä¢ {}", strength));
                        }

                        // Points faibles
                        if (ats.getWeaknesses() != null && !ats.getWeaknesses().isEmpty()) {
                            log.info("   ‚ö†Ô∏è POINTS FAIBLES ({} identifi√©s):", ats.getWeaknesses().size());
                            ats.getWeaknesses().forEach(weakness -> log.info("      ‚Ä¢ {}", weakness));
                        }

                        // Recommandations
                        if (ats.getRecommendations() != null && !ats.getRecommendations().isEmpty()) {
                            log.info("   üí° RECOMMANDATIONS ({} suggestions):", ats.getRecommendations().size());
                            ats.getRecommendations().forEach(recommendation -> log.info("      ‚Ä¢ {}", recommendation));
                        }

                        // Mots-cl√©s manquants
                        if (ats.getMissingKeywords() != null && !ats.getMissingKeywords().isEmpty()) {
                            log.info("   üîç MOTS-CL√âS MANQUANTS ({} sugg√©r√©s):", ats.getMissingKeywords().size());
                            ats.getMissingKeywords().forEach(keyword -> log.info("      ‚Ä¢ {}", keyword));
                        }
                    }

                    // M√©tadonn√©es de traitement
                    if (parsedData.getAiMetadata() != null) {
                        log.info("ü§ñ M√âTADONN√âES IA:");
                        log.info("   - Mod√®le utilis√©: {}", parsedData.getAiMetadata().getModelUsed());
                        log.info("   - Langue d√©tect√©e: {}", parsedData.getAiMetadata().getDetectedLanguage());
                        log.info("   - Trait√© le: {}", parsedData.getAiMetadata().getProcessedAt());
                    }

                    log.info("=== FIN DU R√âSULTAT D'ANALYSE ATS ===");


                    log.info("CV processing successful for documentId: {}. Publishing CV_PARSED event.", event.getDocumentId());
                    Message<CvParsedEventDto> message = MessageBuilder.withPayload(parsedData).build();

                    // Tenter d'envoyer le message
                    boolean sent = streamBridge.send(CV_PARSED_BINDING, message);
                    if (!sent) {
                        log.error("Failed to publish CV_PARSED event for documentId: {} (StreamBridge returned false).", event.getDocumentId());
                        // Propager une erreur pour d√©clencher retry/DLQ
                        return Mono.error(new RuntimeException("Failed to publish CV_PARSED event for documentId: " + event.getDocumentId()));
                    }
                    long duration = System.currentTimeMillis() - startTime;
                    log.info("Processing pipeline completed successfully for documentId: {} in {} ms.", event.getDocumentId(), duration);
                    return Mono.empty(); // Indiquer le succ√®s de cette √©tape
                })
                // Le .doOnError et .onErrorResume sont g√©r√©s dans RabbitMQStreamConfig pour la publication d'erreur
                // et pour laisser Spring Cloud Stream g√©rer les retries/DLQ.
                .then(); // Retourne Mono<Void>
    }

    /**
     * CORRECTION: T√©l√©charge le PDF depuis le document-service et le retourne en Mono<byte[]>.
     * G√®re les erreurs HTTP et les timeouts.
     *
     * @param documentId L'ID du document √† t√©l√©charger.
     * @return Un Mono contenant le tableau d'octets du PDF, ou une erreur.
     */
    private Mono<byte[]> downloadPdfAsBytes(Long documentId) {
        String downloadUri = "/{id}/download"; // Utiliser la variable de config ?
        log.info("üîΩ D√âBUT T√âL√âCHARGEMENT - Document ID: {}", documentId);
        log.info("   üì° URL de t√©l√©chargement: {}", downloadUri);
        log.info("   üåê Service cible: document-management-service");

        return documentServiceWebClient.get()
                .uri(downloadUri, documentId)
                .retrieve()
                // Gestion sp√©cifique des erreurs HTTP
                .onStatus(HttpStatusCode::is4xxClientError, clientResponse ->
                        clientResponse.bodyToMono(String.class).defaultIfEmpty("[No error body]")
                                .flatMap(errorBody -> {
                                    log.error("Client error downloading document {}: Status={}, Body={}", documentId, clientResponse.statusCode(), errorBody);
                                    if (clientResponse.statusCode() == HttpStatus.NOT_FOUND) {
                                        return Mono.error(new DocumentFetchException("Document " + documentId + " not found in document-service."));
                                    }
                                    return Mono.error(new DocumentFetchException("Client error fetching document " + documentId + ": " + clientResponse.statusCode()));
                                })
                )
                .onStatus(HttpStatusCode::is5xxServerError, clientResponse ->
                        clientResponse.bodyToMono(String.class).defaultIfEmpty("[No error body]")
                                .flatMap(errorBody -> {
                                    log.error("Server error downloading document {}: Status={}, Body={}", documentId, clientResponse.statusCode(), errorBody);
                                    return Mono.error(new DocumentFetchException("Server error at document-service for document " + documentId + ": " + clientResponse.statusCode()));
                                })
                )
                // R√©cup√©rer le corps comme Flux<DataBuffer> et joindre en byte[]
                .bodyToFlux(DataBuffer.class)
                .map(DataBuffer::asByteBuffer) // Convertir en ByteBuffer
                .collectList() // Collecter tous les ByteBuffers
                .map(list -> { // Concat√©ner les ByteBuffers en un seul byte[]
                    int totalSize = list.stream().mapToInt(ByteBuffer::remaining).sum();
                    ByteBuffer combined = ByteBuffer.allocate(totalSize);
                    list.forEach(combined::put);
                    return combined.array();
                })
                .doOnSuccess(bytes -> {
                    log.info("‚úÖ T√âL√âCHARGEMENT R√âUSSI - Document ID: {}", documentId);
                    log.info("   üì¶ Taille du fichier: {} bytes ({} KB)", bytes.length, bytes.length / 1024);
                    log.info("   üîç Type de contenu: PDF");
                    log.info("   ‚è±Ô∏è Pr√™t pour l'extraction de texte");
                })
                // G√©rer le cas o√π le corps est vide (succ√®s HTTP mais pas de contenu)
                .filter(bytes -> bytes.length > 0)
                .switchIfEmpty(Mono.error(new DocumentFetchException("Document " + documentId + " downloaded with empty content.")))
                // Ajouter un timeout global pour l'op√©ration de t√©l√©chargement
                // Le timeout est d√©j√† configur√© sur le WebClient, mais on peut en ajouter un sp√©cifique ici si besoin
                // .timeout(Duration.ofSeconds(30))
                // Mapper les autres erreurs potentielles (ex: timeout, connexion)
                .onErrorMap(e -> !(e instanceof DocumentFetchException || e instanceof WebClientResponseException),
                        e -> new DocumentFetchException("Network or unexpected error during document download for id " + documentId, e));
    }
}